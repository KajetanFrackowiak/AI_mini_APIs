{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeeEOHc2EzLC7v3U1EkSWi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "654fb1de05034b18ab5551c6d202a806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a7875d229544f5d8569ae7ee2d44681",
              "IPY_MODEL_83e6f9535f8243058614f2a2fada57c1",
              "IPY_MODEL_90c5f3d69aa74ab49887b0f6244fce68"
            ],
            "layout": "IPY_MODEL_bf47534addc04c6887640c86dc7cc832"
          }
        },
        "1a7875d229544f5d8569ae7ee2d44681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3015fa3997d14636a1dac0947c8a4ff5",
            "placeholder": "​",
            "style": "IPY_MODEL_9003ce9e31c44109bef0b8c01aff6715",
            "value": "Batches: 100%"
          }
        },
        "83e6f9535f8243058614f2a2fada57c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8bf575971bf4ca19508eedebc065a4e",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8efc2c33cb024730ad11a53dde910845",
            "value": 5
          }
        },
        "90c5f3d69aa74ab49887b0f6244fce68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82e4fe229df342afbccc98c62d5a5676",
            "placeholder": "​",
            "style": "IPY_MODEL_1ae7c2d2b0464543af49bae0cd12e70b",
            "value": " 5/5 [00:43&lt;00:00,  7.76s/it]"
          }
        },
        "bf47534addc04c6887640c86dc7cc832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3015fa3997d14636a1dac0947c8a4ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9003ce9e31c44109bef0b8c01aff6715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8bf575971bf4ca19508eedebc065a4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8efc2c33cb024730ad11a53dde910845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82e4fe229df342afbccc98c62d5a5676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ae7c2d2b0464543af49bae0cd12e70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KajetanFrackowiak/AI_mini_APIs/blob/main/FirstQAPipelineWithRAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WAV8FR7UxRmY"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "pip -q install haystack-ai\n",
        "pip -q install \"datasets>=2.6.1\"\n",
        "pip -q install \"sentence-transformers>=3.0.0\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.telemetry import tutorial_running\n",
        "tutorial_running(27)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZlozma-xgQY",
        "outputId": "91b68230-60cb-40e0-b6f2-8682d5f8c054"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/haystack/core/errors.py:34: DeprecationWarning: PipelineMaxLoops is deprecated and will be remove in version '2.7.0'; use PipelineMaxComponentRuns instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
        "document_store = InMemoryDocumentStore()"
      ],
      "metadata": {
        "id": "pBfB1AcFywag"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from haystack import Document\n",
        "\n",
        "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
        "docs = [Document(content=doc[\"content\"], meta=doc[\"meta\"]) for doc in dataset]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QoUa2DMzI5Y",
        "outputId": "0db88c05-e1d6-4f73-fb0f-feeb3669735e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
        "\n",
        "doc_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "doc_embedder.warm_up()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNR9ucBEz8Vc",
        "outputId": "656de1a0-0466-4dac-99f1-456b8f152479"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_with_embeddings = doc_embedder.run(docs)\n",
        "document_store.write_documents(docs_with_embeddings[\"documents\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "654fb1de05034b18ab5551c6d202a806",
            "1a7875d229544f5d8569ae7ee2d44681",
            "83e6f9535f8243058614f2a2fada57c1",
            "90c5f3d69aa74ab49887b0f6244fce68",
            "bf47534addc04c6887640c86dc7cc832",
            "3015fa3997d14636a1dac0947c8a4ff5",
            "9003ce9e31c44109bef0b8c01aff6715",
            "c8bf575971bf4ca19508eedebc065a4e",
            "8efc2c33cb024730ad11a53dde910845",
            "82e4fe229df342afbccc98c62d5a5676",
            "1ae7c2d2b0464543af49bae0cd12e70b"
          ]
        },
        "id": "VbGWdww80hHp",
        "outputId": "295c7d7a-9974-4ce9-fd8f-694b15be5201"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "654fb1de05034b18ab5551c6d202a806"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
        "\n",
        "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "Xd-7WY3h1s5V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
        "\n",
        "retriever = InMemoryEmbeddingRetriever(document_store)"
      ],
      "metadata": {
        "id": "_3UzR4hd2ScI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.components.builders import PromptBuilder\n",
        "\n",
        "template = \"\"\"\n",
        "Given the following information, answer the question.\n",
        "\n",
        "Context:\n",
        "{% for document in documents %}\n",
        "    {{ document.content }}\n",
        "{% endfor %}\n",
        "\n",
        "Question: {{question}}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt_builder = PromptBuilder(template=template)\n"
      ],
      "metadata": {
        "id": "XZlPMtEn24ih"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACE_API_KEY\"] = \"YOUR KEY""
      ],
      "metadata": {
        "id": "d8dirTqEEQVQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.components.generators import HuggingFaceAPIGenerator\n",
        "from haystack.utils import Secret\n",
        "\n",
        "# Retrieve the API key from the environment variable\n",
        "api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
        "\n",
        "# Correct URL for the inference endpoint\n",
        "endpoint_url = \"https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta\"\n",
        "\n",
        "generator = HuggingFaceAPIGenerator(\n",
        "    api_type=\"inference_endpoints\",\n",
        "    api_params={\"url\": endpoint_url},\n",
        "    token=Secret.from_token(api_key)\n",
        ")\n",
        "\n",
        "result = generator.run(prompt=\"What's Natural Language Processing?\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0TxrgT83ofd",
        "outputId": "bf58e1a3-de87-4ad0-cdd4-369cd0e99ee8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/inference/_client.py:2232: FutureWarning: `stop_sequences` is a deprecated argument for `text_generation` task and will be removed in version '0.28.0'. Use `stop` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'replies': ['\\n\\nNatural Language Processing (NLP) is a subfield of Artificial Intelligence (AI) and Computer Science that deals with the interactions between computers and human (natural) languages. NLP is a complex field that involves a variety of techniques from linguistics, computer science, and artificial intelligence.\\n\\nNLP is used to enable computers to understand, interpret, and generate human language. It is a critical component of many AI applications, including virtual assistants, chatbots, search engines, and language translation services.\\n\\nNLP is essential for AI systems to understand and respond to human language in a more natural and intuitive way. It allows computers to process and analyze large volumes of text, identify patterns and relationships, and generate insights and recommendations based on that analysis.\\n\\nNLP is also used to improve the accuracy and efficiency of language translation services, making it easier for people to communicate across language barriers.\\n\\nIn summary, NLP is a critical component of AI that enables computers to understand, interpret, and generate human language, making it possible for AI systems to interact with humans in a more natural and intuitive way.'], 'meta': [{'model': 'https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta', 'finish_reason': 'eos_token', 'usage': {'completion_tokens': 236}}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "basic_rag_pipeline = Pipeline()\n",
        "basic_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
        "basic_rag_pipeline.add_component(\"retriever\", retriever)\n",
        "basic_rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
        "basic_rag_pipeline.add_component(\"generator\", generator)\n",
        "\n",
        "basic_rag_pipeline.connect(\"text_embedder\", \"retriever\")\n",
        "basic_rag_pipeline.connect(\"retriever\", \"prompt_builder\")\n",
        "basic_rag_pipeline.connect(\"prompt_builder\", \"generator\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2gOSmKk4Dvu",
        "outputId": "a6f85dcd-b02d-4641-938b-f88b0a7c2924"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<haystack.core.pipeline.pipeline.Pipeline object at 0x7a710f52b730>\n",
              "🚅 Components\n",
              "  - text_embedder: SentenceTransformersTextEmbedder\n",
              "  - retriever: InMemoryEmbeddingRetriever\n",
              "  - prompt_builder: PromptBuilder\n",
              "  - generator: HuggingFaceAPIGenerator\n",
              "🛤️ Connections\n",
              "  - text_embedder.embedding -> retriever.query_embedding (List[float])\n",
              "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
              "  - prompt_builder.prompt -> generator.prompt (str)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "1CziuWroFQW-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def generate_response(question):\n",
        "  response = basic_rag_pipeline.run({\"text_embedder\": {\"text\": question}})\n",
        "\n",
        "  replies = response.get(\"generator\", {}).get(\"replies\", [])\n",
        "  if replies:\n",
        "    return replies[0]\n",
        "  else:\n",
        "    return \"No replies found\"\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=generate_response,\n",
        "    # Access input and output components from gr.components\n",
        "    inputs=gr.components.Textbox(lines=2, placeholder=\"Enter your question\"),\n",
        "    outputs=gr.components.Textbox(),\n",
        "    title=\"Zephyr Response Generator\",\n",
        "    description=\"Ask a question and get a response from the Zephyr model.\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "DrhvCX1D9IFO",
        "outputId": "43324070-2271-4d3a-f969-3a96c030eb2d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ea4b6f55351251711a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ea4b6f55351251711a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5n_JBYxx9jot"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
